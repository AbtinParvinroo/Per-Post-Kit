{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11828c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class InverseDifferencing:\n",
    "    \"\"\"\n",
    "    بازگردانی تفاضل‌گیری در سری زمانی.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str, default='cumsum'\n",
    "        روش بازگردانی (فعلاً فقط 'cumsum' پشتیبانی می‌شود).\n",
    "    config : dict, optional\n",
    "        تنظیمات:\n",
    "            - order : int, default=1\n",
    "                مرتبه تفاضل‌گیری.\n",
    "            - initial_values : list or dict, optional\n",
    "                مقادیر اولیه برای هر ستون. اگر دیتافریم است، باید به تعداد ستون‌ها یا به صورت دیکشنری {ستون: مقدار} باشد.\n",
    "            - columns : list, optional\n",
    "                نام ستون‌هایی که باید بازگردانی شوند. اگر None، همه ستون‌های عددی.\n",
    "    \"\"\"\n",
    "    def __init__(self, method='cumsum', config=None):\n",
    "        self.method = method\n",
    "        self.config = config or {}\n",
    "        self.columns = self.config.get('columns', None)\n",
    "        self.order = self.config.get('order', 1)\n",
    "        self.initial_values = self.config.get('initial_values', None)\n",
    "        self.fitted_columns_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"بررسی وجود ستون‌ها و تطابق initial_values.\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            if self.columns is None:\n",
    "                self.fitted_columns_ = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            else:\n",
    "                self.fitted_columns_ = [col for col in self.columns if col in X.columns]\n",
    "                missing = set(self.columns) - set(self.fitted_columns_)\n",
    "                if missing:\n",
    "                    raise ValueError(f\"Columns not found: {missing}\")\n",
    "        else:\n",
    "            # اگر X آرایه است، ستون‌ها را با اندیس فرض می‌کنیم\n",
    "            n_features = X.shape[1] if X.ndim > 1 else 1\n",
    "            if self.columns is None:\n",
    "                self.fitted_columns_ = list(range(n_features))\n",
    "            else:\n",
    "                self.fitted_columns_ = self.columns\n",
    "\n",
    "        # بررسی initial_values\n",
    "        if self.initial_values is not None:\n",
    "            if isinstance(self.initial_values, (int, float)):\n",
    "                # یک مقدار برای همه ستون‌ها\n",
    "                self.initial_values = [self.initial_values] * len(self.fitted_columns_)\n",
    "            elif isinstance(self.initial_values, dict):\n",
    "                # تبدیل به لیست به ترتیب ستون‌ها\n",
    "                self.initial_values = [self.initial_values.get(col, None) for col in self.fitted_columns_]\n",
    "            elif isinstance(self.initial_values, (list, np.ndarray)):\n",
    "                if len(self.initial_values) != len(self.fitted_columns_):\n",
    "                    raise ValueError(\"Length of initial_values must match number of columns.\")\n",
    "            else:\n",
    "                raise TypeError(\"initial_values must be a number, dict, or list.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"اعمال بازگردانی تفاضل.\"\"\"\n",
    "        if not hasattr(self, 'fitted_columns_'):\n",
    "            raise RuntimeError(\"Fit must be called before transform.\")\n",
    "\n",
    "        X_out = X.copy() if isinstance(X, pd.DataFrame) else np.copy(X)\n",
    "        for i, col in enumerate(self.fitted_columns_):\n",
    "            # استخراج سری\n",
    "            if isinstance(X_out, pd.DataFrame):\n",
    "                series = X_out[col].values\n",
    "            else:\n",
    "                series = X_out[:, col] if X_out.ndim > 1 else X_out[:]\n",
    "\n",
    "            # بازگردانی با تجمعی\n",
    "            if self.method == 'cumsum':\n",
    "                # نیاز به مقادیر اولیه\n",
    "                if self.initial_values is not None:\n",
    "                    init = self.initial_values[i]\n",
    "                    # برای تفاضل مرتبه d، باید d مقدار اولیه داشته باشیم؟\n",
    "                    # فعلاً فرض می‌کنیم initial_values شامل مقدار قبل از اولین تفاضل است\n",
    "                    # برای مرتبه 1: restored[0] = init + series[0]\n",
    "                    restored = np.zeros_like(series)\n",
    "                    restored[0] = init + series[0] if init is not None else series[0]\n",
    "                    for t in range(1, len(series)):\n",
    "                        restored[t] = restored[t-1] + series[t]\n",
    "                else:\n",
    "                    # اگر initial_values داده نشده، از صفر شروع می‌کنیم\n",
    "                    restored = np.cumsum(series)\n",
    "            else:\n",
    "                raise ValueError(f\"Method '{self.method}' not supported.\")\n",
    "\n",
    "            # قرار دادن در خروجی\n",
    "            if isinstance(X_out, pd.DataFrame):\n",
    "                X_out[col] = restored\n",
    "            else:\n",
    "                if X_out.ndim > 1:\n",
    "                    X_out[:, col] = restored\n",
    "                else:\n",
    "                    X_out[:] = restored\n",
    "\n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c03e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Smoothing:\n",
    "    \"\"\"\n",
    "    هموارسازی سری زمانی.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str, default='moving_average'\n",
    "        'moving_average' یا 'exponential'.\n",
    "    config : dict, optional\n",
    "        تنظیمات:\n",
    "            - window : int, default=3\n",
    "                اندازه پنجره برای میانگین متحرک.\n",
    "            - alpha : float, default=0.3\n",
    "                ضریب هموارسازی نمایی (بین ۰ و ۱).\n",
    "            - min_periods : int, optional\n",
    "                حداقل تعداد داده برای محاسبه (برای ابتدای سری).\n",
    "            - center : bool, default=False\n",
    "                آیا پنجره مرکزی باشد یا به سمت چپ.\n",
    "            - columns : list, optional\n",
    "                ستون‌های هدف.\n",
    "            - suffix : str, default='_smoothed'\n",
    "                پسوند برای ستون‌های جدید.\n",
    "    \"\"\"\n",
    "    def __init__(self, method='moving_average', config=None):\n",
    "        self.method = method\n",
    "        self.config = config or {}\n",
    "        self.columns = self.config.get('columns', None)\n",
    "        self.window = self.config.get('window', 3)\n",
    "        self.alpha = self.config.get('alpha', 0.3)\n",
    "        self.min_periods = self.config.get('min_periods', 1)\n",
    "        self.center = self.config.get('center', False)\n",
    "        self.suffix = self.config.get('suffix', '_smoothed')\n",
    "        self.fitted_columns_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"تعیین ستون‌های هدف.\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            if self.columns is None:\n",
    "                self.fitted_columns_ = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            else:\n",
    "                self.fitted_columns_ = [col for col in self.columns if col in X.columns]\n",
    "                missing = set(self.columns) - set(self.fitted_columns_)\n",
    "                if missing:\n",
    "                    raise ValueError(f\"Columns not found: {missing}\")\n",
    "        else:\n",
    "            n_features = X.shape[1] if X.ndim > 1 else 1\n",
    "            if self.columns is None:\n",
    "                self.fitted_columns_ = list(range(n_features))\n",
    "            else:\n",
    "                self.fitted_columns_ = self.columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"اعمال هموارسازی و افزودن ستون‌های جدید.\"\"\"\n",
    "        X_out = X.copy() if isinstance(X, pd.DataFrame) else np.copy(X)\n",
    "        for col in self.fitted_columns_:\n",
    "            if isinstance(X_out, pd.DataFrame):\n",
    "                series = X_out[col]\n",
    "            else:\n",
    "                series = X_out[:, col] if X_out.ndim > 1 else X_out[:]\n",
    "\n",
    "            if self.method == 'moving_average':\n",
    "                smoothed = series.rolling(window=self.window, min_periods=self.min_periods, center=self.center).mean()\n",
    "            elif self.method == 'exponential':\n",
    "                # استفاده از pandas ewm\n",
    "                smoothed = series.ewm(alpha=self.alpha, adjust=False).mean()\n",
    "            else:\n",
    "                raise ValueError(f\"Method '{self.method}' not supported.\")\n",
    "\n",
    "            # اضافه کردن به عنوان ستون جدید\n",
    "            if isinstance(X_out, pd.DataFrame):\n",
    "                new_col = f\"{col}{self.suffix}\"\n",
    "                X_out[new_col] = smoothed\n",
    "            else:\n",
    "                # برای آرایه، ستون جدید اضافه می‌کنیم (باعث تغییر شکل می‌شود)\n",
    "                # بهتر است آرایه را به DataFrame تبدیل کنیم یا با احتیاط کار کنیم.\n",
    "                # در اینجا فرض می‌کنیم X DataFrame است.\n",
    "                raise NotImplementedError(\"Smoothing on numpy arrays not fully implemented; please use DataFrame.\")\n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "import warnings\n",
    "\n",
    "class ResidualDiagnostics:\n",
    "    \"\"\"\n",
    "    تشخیص باقیمانده‌ها و محاسبه آماره‌ها.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str, default='residuals'\n",
    "        فعلاً فقط 'residuals' پشتیبانی می‌شود.\n",
    "    config : dict, optional\n",
    "        تنظیمات:\n",
    "            - prediction_column : str\n",
    "                نام ستون حاوی پیش‌بینی.\n",
    "            - true_column : str\n",
    "                نام ستون حاوی مقادیر واقعی.\n",
    "            - residual_column : str, default='residual'\n",
    "                نام ستون خروجی برای باقیمانده‌ها.\n",
    "            - tests : list, default=['normality', 'acf']\n",
    "                لیست تست‌ها: 'normality', 'acf', 'pacf', 'box_pierce', 'ljung_box'\n",
    "            - lags : int, optional\n",
    "                تعداد لگ‌ها برای تست‌های خودهمبستگی.\n",
    "    \"\"\"\n",
    "    def __init__(self, method='residuals', config=None):\n",
    "        self.method = method\n",
    "        self.config = config or {}\n",
    "        self.pred_col = self.config.get('prediction_column')\n",
    "        self.true_col = self.config.get('true_column')\n",
    "        self.residual_col = self.config.get('residual_column', 'residual')\n",
    "        self.tests = self.config.get('tests', ['normality', 'acf'])\n",
    "        self.lags = self.config.get('lags', 10)\n",
    "        self.results_ = {}  # برای ذخیره نتایج تست‌ها\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"بررسی وجود ستون‌های مورد نیاز.\"\"\"\n",
    "        if self.pred_col is None or self.true_col is None:\n",
    "            raise ValueError(\"prediction_column and true_column must be specified in config.\")\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"X must be a pandas DataFrame.\")\n",
    "        if self.pred_col not in X.columns:\n",
    "            raise ValueError(f\"Prediction column '{self.pred_col}' not found.\")\n",
    "        if self.true_col not in X.columns:\n",
    "            raise ValueError(f\"True column '{self.true_col}' not found.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"محاسبه باقیمانده‌ها و انجام تست‌ها.\"\"\"\n",
    "        X_out = X.copy()\n",
    "        residuals = X_out[self.true_col] - X_out[self.pred_col]\n",
    "        X_out[self.residual_col] = residuals\n",
    "\n",
    "        # انجام تست‌های تشخیصی\n",
    "        self.results_ = {}\n",
    "        res_vals = residuals.dropna().values\n",
    "\n",
    "        if 'normality' in self.tests and len(res_vals) > 3:\n",
    "            # تست شاپیرو-ویلک\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                shapiro_stat, shapiro_p = stats.shapiro(res_vals)\n",
    "            self.results_['shapiro'] = {'statistic': shapiro_stat, 'p_value': shapiro_p}\n",
    "\n",
    "        if 'acf' in self.tests and len(res_vals) > self.lags:\n",
    "            acf_vals = acf(res_vals, nlags=self.lags, fft=False)\n",
    "            self.results_['acf'] = acf_vals.tolist()\n",
    "\n",
    "        if 'pacf' in self.tests and len(res_vals) > self.lags:\n",
    "            pacf_vals = pacf(res_vals, nlags=self.lags)\n",
    "            self.results_['pacf'] = pacf_vals.tolist()\n",
    "\n",
    "        if 'box_pierce' in self.tests and len(res_vals) > self.lags:\n",
    "            from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "            result = acorr_ljungbox(res_vals, lags=[self.lags], boxpierce=True, return_df=False)\n",
    "            self.results_['box_pierce'] = {\n",
    "                'statistic': result[0]['bp_stat'].values[0] if hasattr(result[0], 'bp_stat') else None,\n",
    "                'p_value': result[0]['bp_pvalue'].values[0] if hasattr(result[0], 'bp_pvalue') else None\n",
    "            }\n",
    "\n",
    "        if 'ljung_box' in self.tests and len(res_vals) > self.lags:\n",
    "            from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "            result = acorr_ljungbox(res_vals, lags=[self.lags], boxpierce=False, return_df=False)\n",
    "            self.results_['ljung_box'] = {\n",
    "                'statistic': result[0]['lb_stat'].values[0] if hasattr(result[0], 'lb_stat') else None,\n",
    "                'p_value': result[0]['lb_pvalue'].values[0] if hasattr(result[0], 'lb_pvalue') else None\n",
    "            }\n",
    "\n",
    "        return X_out\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"بازگرداندن نتایج تست‌ها.\"\"\"\n",
    "        return self.results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dba96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfidenceInterval:\n",
    "    \"\"\"\n",
    "    محاسبه بازه اطمینان برای پیش‌بینی‌ها.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str, default='normal'\n",
    "        'normal', 'bootstrap', 'quantile'.\n",
    "    config : dict, optional\n",
    "        تنظیمات:\n",
    "            - prediction_column : str\n",
    "                نام ستون حاوی پیش‌بینی.\n",
    "            - residual_column : str, optional\n",
    "                نام ستون حاوی باقیمانده‌ها (برای روش نرمال و بوت‌استرپ). اگر نباشد، از انحراف معیار پیش‌بینی‌ها استفاده می‌شود.\n",
    "            - confidence_level : float, default=0.95\n",
    "                سطح اطمینان.\n",
    "            - lower_column : str, default='lower_bound'\n",
    "                نام ستون خروجی برای کران پایین.\n",
    "            - upper_column : str, default='upper_bound'\n",
    "                نام ستون خروجی برای کران بالا.\n",
    "            - n_bootstrap : int, default=1000\n",
    "                تعداد نمونه‌های بوت‌استرپ (برای روش bootstrap).\n",
    "            - quantiles : list, optional\n",
    "                چندک‌های دلخواه (برای روش quantile). اگر None، از confidence_level استفاده می‌شود.\n",
    "    \"\"\"\n",
    "    def __init__(self, method='normal', config=None):\n",
    "        self.method = method\n",
    "        self.config = config or {}\n",
    "        self.pred_col = self.config.get('prediction_column')\n",
    "        self.residual_col = self.config.get('residual_column', None)\n",
    "        self.confidence_level = self.config.get('confidence_level', 0.95)\n",
    "        self.lower_col = self.config.get('lower_column', 'lower_bound')\n",
    "        self.upper_col = self.config.get('upper_column', 'upper_bound')\n",
    "        self.n_bootstrap = self.config.get('n_bootstrap', 1000)\n",
    "        self.quantiles = self.config.get('quantiles', None)\n",
    "        self.fitted_ = False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"بررسی ستون‌ها و محاسبه آماره‌های مورد نیاز.\"\"\"\n",
    "        if self.pred_col is None:\n",
    "            raise ValueError(\"prediction_column must be specified in config.\")\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"X must be a pandas DataFrame.\")\n",
    "        if self.pred_col not in X.columns:\n",
    "            raise ValueError(f\"Prediction column '{self.pred_col}' not found.\")\n",
    "\n",
    "        # اگر residual_column داده شده، آن را بررسی می‌کنیم\n",
    "        if self.residual_col is not None and self.residual_col not in X.columns:\n",
    "            raise ValueError(f\"Residual column '{self.residual_col}' not found.\")\n",
    "\n",
    "        # محاسبه آماره‌ها بر اساس روش\n",
    "        if self.method == 'normal':\n",
    "            # محاسبه میانگین و انحراف معیار باقیمانده‌ها (یا پیش‌بینی‌ها)\n",
    "            if self.residual_col:\n",
    "                residuals = X[self.residual_col].dropna()\n",
    "                self.residual_std_ = residuals.std()\n",
    "                self.residual_mean_ = residuals.mean()\n",
    "            else:\n",
    "                # اگر باقیمانده نداریم، از خود پیش‌بینی‌ها؟ معمولاً نمی‌شود.\n",
    "                # در عوض می‌توان از خطای استاندارد پیش‌بینی استفاده کرد.\n",
    "                # در اینجا ساده‌سازی: انحراف معیار پیش‌بینی‌ها\n",
    "                preds = X[self.pred_col].dropna()\n",
    "                self.residual_std_ = preds.std()\n",
    "                self.residual_mean_ = 0\n",
    "        elif self.method == 'bootstrap':\n",
    "            # نیاز به داده برای نمونه‌گیری مجدد\n",
    "            if self.residual_col is None:\n",
    "                raise ValueError(\"bootstrap method requires residual_column to resample.\")\n",
    "            self.residuals_ = X[self.residual_col].dropna().values\n",
    "        elif self.method == 'quantile':\n",
    "            if self.quantiles is None:\n",
    "                alpha = 1 - self.confidence_level\n",
    "                self.quantiles = [alpha/2, 1 - alpha/2]\n",
    "        else:\n",
    "            raise ValueError(f\"Method '{self.method}' not supported.\")\n",
    "\n",
    "        self.fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"محاسبه کران‌های بازه اطمینان برای هر نمونه.\"\"\"\n",
    "        if not self.fitted_:\n",
    "            raise RuntimeError(\"Fit must be called before transform.\")\n",
    "        if self.pred_col not in X.columns:\n",
    "            raise ValueError(f\"Prediction column '{self.pred_col}' not found in transform data.\")\n",
    "\n",
    "        X_out = X.copy()\n",
    "        preds = X_out[self.pred_col].values\n",
    "\n",
    "        if self.method == 'normal':\n",
    "            # فاصله بر اساس توزیع نرمال\n",
    "            z = stats.norm.ppf(1 - (1 - self.confidence_level) / 2)\n",
    "            margin = z * self.residual_std_\n",
    "            lower = preds - margin\n",
    "            upper = preds + margin\n",
    "        elif self.method == 'bootstrap':\n",
    "            # برای هر نمونه، با جایگذاری مجدد از باقیمانده‌ها نمونه می‌گیریم و چندک محاسبه می‌کنیم\n",
    "            # این روش می‌تواند سنگین باشد. راه ساده‌تر: ساختن توزیع bootstrap برای هر نمونه؟\n",
    "            # در عمل، معمولاً بازه‌های bootstrap را با نمونه‌گیری از باقیمانده‌ها و ساختن پیش‌بینی‌های جدید محاسبه می‌کنند.\n",
    "            # در اینجا یک پیاده‌سازی ساده: برای هر نمونه، n_bootstrap بار یک باقیمانده تصادفی را به پیش‌بینی اضافه می‌کنیم.\n",
    "            n = len(preds)\n",
    "            lower = np.zeros(n)\n",
    "            upper = np.zeros(n)\n",
    "            for i in range(n):\n",
    "                boot_samples = preds[i] + np.random.choice(self.residuals_, size=self.n_bootstrap, replace=True)\n",
    "                lower[i] = np.percentile(boot_samples, (1 - self.confidence_level) / 2 * 100)\n",
    "                upper[i] = np.percentile(boot_samples, (1 + self.confidence_level) / 2 * 100)\n",
    "        elif self.method == 'quantile':\n",
    "            # استفاده از چندک‌های مشخص\n",
    "            # این روش نیاز به محاسبه چندک‌ها از توزیع پیش‌بینی‌ها دارد، اما اینجا فقط بر اساس داده موجود است.\n",
    "            # اگر چندک‌ها ثابت باشند، برای همه نمونه‌ها یکسان خواهند بود.\n",
    "            # اما کاربر می‌تواند چندک‌هایی مانند [0.025, 0.975] بدهد.\n",
    "            q_low, q_high = self.quantiles[0], self.quantiles[-1]\n",
    "            # از توزیع پیش‌بینی‌ها؟ یا از باقیمانده‌ها؟\n",
    "            # ساده: فرض می‌کنیم پیش‌بینی‌ها نرمال هستند و از چندک‌های نرمال استفاده می‌کنیم.\n",
    "            # اما این در واقع همان روش normal است.\n",
    "            # برای تنوع، می‌توان از چندک‌های تجربی باقیمانده‌ها استفاده کرد.\n",
    "            if self.residual_col is not None and self.residual_col in X.columns:\n",
    "                residuals = X[self.residual_col].values\n",
    "                q_low_val = np.percentile(residuals, q_low * 100)\n",
    "                q_high_val = np.percentile(residuals, q_high * 100)\n",
    "                lower = preds + q_low_val\n",
    "                upper = preds + q_high_val\n",
    "            else:\n",
    "                # از توزیع نرمال با انحراف معیار پیش‌بینی‌ها\n",
    "                std = np.std(preds)\n",
    "                z_low = stats.norm.ppf(q_low)\n",
    "                z_high = stats.norm.ppf(q_high)\n",
    "                lower = preds + z_low * std\n",
    "                upper = preds + z_high * std\n",
    "        else:\n",
    "            raise ValueError(f\"Method '{self.method}' not supported.\")\n",
    "\n",
    "        X_out[self.lower_col] = lower\n",
    "        X_out[self.upper_col] = upper\n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84457bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierDetectionOnPredictions:\n",
    "    \"\"\"\n",
    "    تشخیص نقاط پرت در ستون پیش‌بینی (یا هر ستون عددی).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str, default='zscore'\n",
    "        روش تشخیص: 'zscore', 'iqr', 'isolation_forest', 'dbscan' و ...\n",
    "    config : dict, optional\n",
    "        تنظیمات:\n",
    "            - column : str\n",
    "                نام ستون هدف.\n",
    "            - threshold : float, default=3.0\n",
    "                آستانه برای zscore.\n",
    "            - iqr_multiplier : float, default=1.5\n",
    "                ضریب IQR.\n",
    "            - contamination : float, default=0.1\n",
    "                نسبت outlier برای isolation forest.\n",
    "            - random_state : int, default=42\n",
    "                seed.\n",
    "            - flag_column : str, default='is_outlier'\n",
    "                نام ستون خروجی بولین.\n",
    "            - action : str, optional\n",
    "                'flag', 'remove', 'replace' (فعلاً فقط 'flag' پشتیبانی می‌شود).\n",
    "    \"\"\"\n",
    "    def __init__(self, method='zscore', config=None):\n",
    "        self.method = method\n",
    "        self.config = config or {}\n",
    "        self.column = self.config.get('column')\n",
    "        self.threshold = self.config.get('threshold', 3.0)\n",
    "        self.iqr_multiplier = self.config.get('iqr_multiplier', 1.5)\n",
    "        self.contamination = self.config.get('contamination', 0.1)\n",
    "        self.random_state = self.config.get('random_state', 42)\n",
    "        self.flag_column = self.config.get('flag_column', 'is_outlier')\n",
    "        self.action = self.config.get('action', 'flag')\n",
    "        self.model_ = None\n",
    "        self.fitted_ = False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"یادگیری پارامترهای تشخیص (برای روش‌های مبتنی بر مدل).\"\"\"\n",
    "        if self.column is None:\n",
    "            raise ValueError(\"column must be specified in config.\")\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"X must be a pandas DataFrame.\")\n",
    "        if self.column not in X.columns:\n",
    "            raise ValueError(f\"Column '{self.column}' not found.\")\n",
    "\n",
    "        data = X[self.column].dropna().values.reshape(-1, 1)\n",
    "\n",
    "        if self.method == 'zscore':\n",
    "            self.mean_ = np.mean(data)\n",
    "            self.std_ = np.std(data)\n",
    "        elif self.method == 'iqr':\n",
    "            q1 = np.percentile(data, 25)\n",
    "            q3 = np.percentile(data, 75)\n",
    "            self.q1_ = q1\n",
    "            self.q3_ = q3\n",
    "            self.iqr_ = q3 - q1\n",
    "        elif self.method == 'isolation_forest':\n",
    "            from sklearn.ensemble import IsolationForest\n",
    "            self.model_ = IsolationForest(contamination=self.contamination, random_state=self.random_state)\n",
    "            self.model_.fit(data)\n",
    "        elif self.method == 'dbscan':\n",
    "            from sklearn.cluster import DBSCAN\n",
    "            self.model_ = DBSCAN(eps=self.config.get('eps', 0.5), min_samples=self.config.get('min_samples', 5))\n",
    "            self.model_.fit(data)\n",
    "            # DBSCAN برچسب -1 را outlier می‌دهد\n",
    "        else:\n",
    "            raise ValueError(f\"Method '{self.method}' not supported.\")\n",
    "\n",
    "        self.fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"تشخیص outlier و افزودن پرچم.\"\"\"\n",
    "        if not self.fitted_:\n",
    "            raise RuntimeError(\"Fit must be called before transform.\")\n",
    "        if self.column not in X.columns:\n",
    "            raise ValueError(f\"Column '{self.column}' not found in transform data.\")\n",
    "\n",
    "        X_out = X.copy()\n",
    "        data = X_out[self.column].values.reshape(-1, 1)\n",
    "\n",
    "        if self.method == 'zscore':\n",
    "            z_scores = np.abs((data - self.mean_) / self.std_)\n",
    "            outliers = z_scores.flatten() > self.threshold\n",
    "        elif self.method == 'iqr':\n",
    "            lower = self.q1_ - self.iqr_multiplier * self.iqr_\n",
    "            upper = self.q3_ + self.iqr_multiplier * self.iqr_\n",
    "            outliers = (data < lower) | (data > upper)\n",
    "            outliers = outliers.flatten()\n",
    "        elif self.method == 'isolation_forest':\n",
    "            preds = self.model_.predict(data)\n",
    "            outliers = preds == -1\n",
    "        elif self.method == 'dbscan':\n",
    "            preds = self.model_.fit_predict(data)  # باید دوباره fit کنیم؟ بهتر است در fit انجام شده باشد.\n",
    "            outliers = preds == -1\n",
    "        else:\n",
    "            raise ValueError(f\"Method '{self.method}' not supported.\")\n",
    "\n",
    "        X_out[self.flag_column] = outliers\n",
    "\n",
    "        # اگر action 'replace' باشد، می‌توان outlierها را با میانگین جایگزین کرد\n",
    "        if self.action == 'replace':\n",
    "            replacement = np.mean(data[~outliers]) if np.any(~outliers) else 0\n",
    "            X_out.loc[outliers, self.column] = replacement\n",
    "        elif self.action == 'remove':\n",
    "            X_out = X_out[~outliers].reset_index(drop=True)\n",
    "\n",
    "        return X_out"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
